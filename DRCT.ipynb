{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNveiGP6NbVnYwTe9/+WSu7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_image/blob/main/DRCT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRVQJtkdAzO9"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "!nvidia-smi\n",
        "!git clone https://github.com/ming053l/DRCT.git\n",
        "%cd DRCT\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install basicsr\n",
        "\n",
        "!pip install gdown pillow matplotlib\n",
        "\n",
        "import os\n",
        "import basicsr\n",
        "\n",
        "basicsr_degradations_path = os.path.join(os.path.dirname(basicsr.__file__), 'data', 'degradations.py')\n",
        "\n",
        "!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/g' {basicsr_degradations_path}\n",
        "\n",
        "model_folder = '/content/DRCT/models'\n",
        "\n",
        "if os.path.isdir(model_folder):\n",
        "    shutil.rmtree(model_folder)\n",
        "os.makedirs(model_folder)\n",
        "\n",
        "import gdown\n",
        "\n",
        "\n",
        "files = [\n",
        "    ('1jw2UWAersWZecPq-c_g5RM3mDOoc_cbd', 'DRCT_X4.pth'),\n",
        "    ('1bVxvA6QFbne2se0CQJ-jyHFy94UOi3h5', 'DRCT-L_X4'),\n",
        "    ('1uLGwmSko9uF82X4OPOMw3xfM3stlnYZ-', 'net_g_latest.pth'),\n",
        "    ('1rfV_ExLtfjdHygWGJ3VUYgyn9UkzSwbZ', 'net_g_latest (MSEModel).pth')\n",
        "]\n",
        "\n",
        "for file_id, filename in files:\n",
        "    gdown.download(f'https://drive.google.com/uc?id={file_id}', output=f'/content/DRCT/models/{filename}', quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Upload images** { display-mode: \"form\" }\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "upload_folder = \"/content/DRCT/upload\"\n",
        "result_folder = \"/content/DRCT/results\"\n",
        "\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.makedirs(upload_folder)\n",
        "\n",
        "basepath = os.getcwd()\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(os.path.join(basepath, filename), os.path.join(upload_folder, filename))"
      ],
      "metadata": {
        "id": "iGZHXzONA64X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Run** { display-mode: \"form\" }\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import traceback\n",
        "\n",
        "if os.path.isdir(result_folder):\n",
        "    shutil.rmtree(result_folder)\n",
        "os.makedirs(result_folder)\n",
        "\n",
        "sys.path.append('/content/DRCT')\n",
        "\n",
        "from drct.models.drct_model import DRCTModel\n",
        "\n",
        "def get_model_config(model_type='1'):\n",
        "    opt = {\n",
        "        'task': 'sr',\n",
        "        'scale': 4,\n",
        "        'model_type': 'DRCTModel',\n",
        "        'num_gpu': 1,\n",
        "        'dist': False,\n",
        "        'is_train': False,\n",
        "        'datasets': {\n",
        "            'test': {\n",
        "                'name': 'SingleImageDataset',\n",
        "                'dataroot_lq': None,\n",
        "                'io_backend': {'type': 'disk'}\n",
        "            }\n",
        "        },\n",
        "        'network_g': {\n",
        "            'type': 'DRCT',\n",
        "            'upscale': 4,\n",
        "            'in_chans': 3,\n",
        "            'img_size': 64,\n",
        "            'window_size': 16,\n",
        "            'img_range': 1.,\n",
        "            'depths': [6, 6, 6, 6, 6, 6] if model_type == '1' else [6, 6, 6, 6, 6, 6, 6, 6],\n",
        "            'embed_dim': 180 if model_type == '1' else 240,\n",
        "            'num_heads': [6, 6, 6, 6, 6, 6] if model_type == '1' else [8, 8, 8, 8, 8, 8, 8, 8],\n",
        "            'mlp_ratio': 2,\n",
        "            'upsampler': 'pixelshuffle',\n",
        "            'resi_connection': '1conv'\n",
        "        },\n",
        "        'path': {\n",
        "            'pretrain_network_g': None,\n",
        "            'strict_load_g': True,\n",
        "            'param_key_g': 'params'\n",
        "        }\n",
        "    }\n",
        "    return opt\n",
        "\n",
        "def get_model_path(model_name):\n",
        "    model_paths = {\n",
        "        \"DRCT_X4.pth\": \"/content/DRCT/models/DRCT_X4.pth\",\n",
        "        \"DRCT-L_X4\": \"/content/DRCT/models/DRCT-L_X4\",\n",
        "        \"net_g_latest.pth\": \"/content/DRCT/models/net_g_latest.pth\",\n",
        "        \"net_g_latest (MSEModel).pth\": \"/content/DRCT/models/net_g_latest (MSEModel).pth\"\n",
        "    }\n",
        "    return model_paths.get(model_name)\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    w_orig, h_orig = img.size\n",
        "    print(f\"Original image dimensions: {w_orig}x{h_orig}\")\n",
        "\n",
        "    new_w = ((w_orig + 15) // 16) * 16\n",
        "    new_h = ((h_orig + 15) // 16) * 16\n",
        "\n",
        "    delta_w = new_w - w_orig\n",
        "    delta_h = new_h - h_orig\n",
        "\n",
        "    padding = (delta_w // 2, delta_h // 2, delta_w - delta_w // 2, delta_h - delta_h // 2)\n",
        "\n",
        "    if delta_w != 0 or delta_h != 0:\n",
        "        print(f\"Adding transparent padding to dimensions: {new_w}x{new_h}\")\n",
        "        img = img.crop((-padding[0], -padding[1], w_orig + padding[2], h_orig + padding[3]))\n",
        "    else:\n",
        "        print(\"Image dimensions are already multiples of 16, no padding needed.\")\n",
        "\n",
        "    return img, padding, (w_orig, h_orig)\n",
        "\n",
        "def split_image_into_tiles(img, tile_size):\n",
        "    w, h = img.size\n",
        "    tiles = []\n",
        "    positions = []\n",
        "    for y in range(0, h, tile_size):\n",
        "        for x in range(0, w, tile_size):\n",
        "            tile = img.crop((x, y, min(x + tile_size, w), min(y + tile_size, h)))\n",
        "            tiles.append(tile)\n",
        "            positions.append((x, y))\n",
        "    return tiles, positions\n",
        "\n",
        "def merge_tiles(tiles, positions, img_size):\n",
        "    upscaled_img = Image.new('RGB', img_size)\n",
        "    for tile, (x, y) in zip(tiles, positions):\n",
        "        upscaled_img.paste(tile, (x, y))\n",
        "    return upscaled_img\n",
        "\n",
        "def postprocess_image(tensor):\n",
        "    output = tensor.squeeze(0).cpu().clamp_(0, 1)\n",
        "    output = transforms.ToPILImage()(output)\n",
        "    return output\n",
        "\n",
        "model_name = \"net_g_latest (MSEModel).pth\"  #@param [\"DRCT_X4.pth\", \"DRCT-L_X4\", \"net_g_latest.pth\", \"net_g_latest (MSEModel).pth\"]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Loading model to device: {device}\")\n",
        "\n",
        "opt = get_model_config('1' if model_name in ['DRCT_X4.pth', 'net_g_latest.pth', 'net_g_latest (MSEModel).pth'] else '2')\n",
        "model = DRCTModel(opt)\n",
        "model_path = get_model_path(model_name)\n",
        "\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "if 'params_ema' in checkpoint:\n",
        "    model.net_g.load_state_dict(checkpoint['params_ema'], strict=True)\n",
        "elif 'params' in checkpoint:\n",
        "    model.net_g.load_state_dict(checkpoint['params'], strict=True)\n",
        "else:\n",
        "    model.net_g.load_state_dict(checkpoint, strict=True)\n",
        "\n",
        "model.net_g = model.net_g.to(device)\n",
        "model.net_g.eval()\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "for filename in os.listdir(upload_folder):\n",
        "    input_path = os.path.join(upload_folder, filename)\n",
        "    output_path = os.path.join(result_folder, f'upscaled_{filename}')\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nProcessing {filename}\")\n",
        "\n",
        "        img, padding, (w_orig, h_orig) = load_and_preprocess_image(input_path)\n",
        "\n",
        "        tile_size = 512\n",
        "        tiles, positions = split_image_into_tiles(img, tile_size)\n",
        "\n",
        "        upscaled_tiles = []\n",
        "        for idx, tile in enumerate(tiles):\n",
        "            print(f\"Processing tile {idx+1}/{len(tiles)}\")\n",
        "            input_tensor = transform(tile).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model.net_g(input_tensor)\n",
        "\n",
        "            output_image = postprocess_image(output)\n",
        "            upscaled_tiles.append(output_image)\n",
        "\n",
        "            del input_tensor\n",
        "            del output\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        scale = 4\n",
        "        upscaled_w = img.size[0] * scale\n",
        "        upscaled_h = img.size[1] * scale\n",
        "        upscaled_img = merge_tiles(upscaled_tiles, [(x * scale, y * scale) for x, y in positions], (upscaled_w, upscaled_h))\n",
        "\n",
        "        pad_left, pad_top, pad_right, pad_bottom = [p * scale for p in padding]\n",
        "        upscaled_img = upscaled_img.crop((pad_left, pad_top, upscaled_w - pad_right, upscaled_h - pad_bottom))\n",
        "\n",
        "        expected_w, expected_h = w_orig * scale, h_orig * scale\n",
        "        upscaled_img = upscaled_img.resize((expected_w, expected_h), Image.LANCZOS)\n",
        "\n",
        "        upscaled_img.save(output_path)\n",
        "        print(f\"Image successfully processed and saved to {output_path}\")\n",
        "\n",
        "        del img\n",
        "        del upscaled_img\n",
        "        del upscaled_tiles\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filename}: {str(e)}\")\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "NpWpTcEFA_be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Visualize** { display-mode: \"form\" }\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def is_image_file(filename):\n",
        "    # Common image file extensions\n",
        "    image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}\n",
        "    return os.path.splitext(filename.lower())[1] in image_extensions\n",
        "\n",
        "def resize_image_maintain_aspect(image, max_width, target_height=None):\n",
        "    width, height = image.size\n",
        "    if width > max_width:\n",
        "        new_height = int(height * max_width / width)\n",
        "        image = image.resize((max_width, new_height))\n",
        "\n",
        "    # If target_height is specified, resize to match that height\n",
        "    if target_height is not None and image.size[1] != target_height:\n",
        "        new_width = int(image.size[0] * target_height / image.size[1])\n",
        "        image = image.resize((new_width, target_height))\n",
        "\n",
        "    return image\n",
        "\n",
        "filenames_upload = [f for f in os.listdir(upload_folder) if is_image_file(f)]\n",
        "filenames_upload.sort()\n",
        "\n",
        "filenames_output = [f for f in os.listdir(result_folder) if is_image_file(f)]\n",
        "filenames_output.sort()\n",
        "\n",
        "for filename_in, filename_out in zip(filenames_upload, filenames_output):\n",
        "    image_original = PIL.Image.open(os.path.join(upload_folder, filename_in))\n",
        "    image_restore = PIL.Image.open(os.path.join(result_folder, filename_out))\n",
        "\n",
        "    max_width = 500\n",
        "\n",
        "    # First resize both images to max_width if needed\n",
        "    image_original = resize_image_maintain_aspect(image_original, max_width)\n",
        "    image_restore = resize_image_maintain_aspect(image_restore, max_width)\n",
        "\n",
        "    # Get the minimum height between the two images\n",
        "    target_height = min(image_original.size[1], image_restore.size[1])\n",
        "\n",
        "    # Resize both images to have the same height\n",
        "    image_original = resize_image_maintain_aspect(image_original, max_width, target_height)\n",
        "    image_restore = resize_image_maintain_aspect(image_restore, max_width, target_height)\n",
        "\n",
        "    # Convert images to RGB mode if they're not already\n",
        "    if image_original.mode != 'RGB':\n",
        "        image_original = image_original.convert('RGB')\n",
        "    if image_restore.mode != 'RGB':\n",
        "        image_restore = image_restore.convert('RGB')\n",
        "\n",
        "    # Create the side-by-side comparison\n",
        "    comparison = PIL.Image.fromarray(np.hstack((np.array(image_original), np.array(image_restore))))\n",
        "    display(comparison)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "Ov8Nj0s0CM8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Download results** { display-mode: \"form\" }\n",
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "def is_image_file(filename):\n",
        "    image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}\n",
        "    return os.path.splitext(filename.lower())[1] in image_extensions\n",
        "\n",
        "files_in_folder = [f for f in os.listdir(result_folder) if is_image_file(f)]\n",
        "zip_file = \"download.zip\"\n",
        "\n",
        "if len(files_in_folder) == 1:\n",
        "    file_to_download = os.path.join(result_folder, files_in_folder[0])\n",
        "    files.download(file_to_download)\n",
        "else:\n",
        "    zip_path = os.path.join(result_folder, zip_file)\n",
        "    if os.path.exists(zip_path):\n",
        "        os.remove(zip_path)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for file in files_in_folder:\n",
        "            file_path = os.path.join(result_folder, file)\n",
        "            zipf.write(file_path, file)\n",
        "\n",
        "    files.download(zip_path)"
      ],
      "metadata": {
        "id": "BegL27CdCQXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}