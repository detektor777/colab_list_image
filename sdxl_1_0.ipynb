{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_image/blob/main/sdxl_1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOB3MpHU18-U"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "!pip install -q invisible_watermark transformers accelerate safetensors diffusers controlnet_aux==0.0.7 xformers mediapy\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLImg2ImgPipeline, DiffusionPipeline, KDPM2AncestralDiscreteScheduler, StableDiffusionXLPipeline, AutoencoderKL\n",
        "import gc\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "import os\n",
        "import random\n",
        "model_base = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "v_autoencoder = \"madebyollin/sdxl-vae-fp16-fix\" # fix vae for run in fp16 precision without generating NaNs\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(v_autoencoder, torch_dtype=torch.float16)\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    model_base,\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        "    add_watermarker=False, # no watermarker\n",
        "    )\n",
        "\n",
        "pipe.safety_checker = None\n",
        "\n",
        "pipe.to(\"cuda\")\n",
        "model_refiner = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
        "\n",
        "pipe_refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "    model_refiner,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        "    add_watermarker=False, # no watermarker\n",
        "    )\n",
        "\n",
        "#pipe_refiner.to(\"cuda\")\n",
        "pipe_refiner.enable_model_cpu_offload()\n",
        "#(Optional) Change the scheduler\n",
        "pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(\n",
        "pipe.scheduler.config, use_karras_sigmas=False\n",
        ")\n",
        "#generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import gc\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from diffusers import DPMSolverMultistepScheduler, EulerDiscreteScheduler\n",
        "from diffusers import KDPM2DiscreteScheduler, KDPM2AncestralDiscreteScheduler\n",
        "from diffusers import EulerAncestralDiscreteScheduler, HeunDiscreteScheduler\n",
        "from diffusers import LMSDiscreteScheduler\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "save_dir = './samples_sdxl'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)\n",
        "\n",
        "def set_sampler(pipe, sampler_name):\n",
        "    if sampler_name == \"euler\":\n",
        "        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "    return pipe\n",
        "\n",
        "def set_scheduler(pipe, scheduler_name, num_steps):\n",
        "    if scheduler_name == \"karras\":\n",
        "        pipe.scheduler.use_karras_sigmas = True\n",
        "    elif scheduler_name == \"exponential\":\n",
        "        pipe.scheduler.set_timesteps(num_steps, decay_rate=0.5)\n",
        "    return pipe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Create** { display-mode: \"form\" }\n",
        "prompt =  \"cyberpunk, cat, Ukrainian flag\" #@param {type:\"string\"}\n",
        "prompt2 = \"\" #@param {type:\"string\"}\n",
        "negative_prompt = '' #@param {type:\"string\"}\n",
        "negative_prompt2 = '' #@param {type:\"string\"}\n",
        "scale = 9 #@param {type:\"integer\"}\n",
        "steps = 50 #@param {type:\"integer\"}\n",
        "height = 1024 #@param {type:\"integer\"}\n",
        "width = 1024 #@param {type:\"integer\"}\n",
        "sampler_name = \"LMS\" #@param ['euler', 'LMS', 'ddim', 'heun', \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heunpp2\", \"dpm_2\", \"dpm_2_ancestral\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"Icm\", \"ipndm\", \"ipndm_v\", \"deis\", \"uni_pc\", \"uni_pc_bh2\"]\n",
        "scheduler_name = \"karras\" #@param ['simple', 'karras', 'normal', 'exponential', 'sgm_uniform' , 'ddim_uniform' , 'beta']\n",
        "\n",
        "params = {\n",
        "    \"prompt\": prompt,\n",
        "    \"prompt_2\": prompt2,\n",
        "    \"height\": height,\n",
        "    \"width\": width,\n",
        "    \"negative_prompt\": negative_prompt,\n",
        "    \"negative_prompt_2\": negative_prompt2,\n",
        "    \"guidance_scale\": scale,\n",
        "    \"num_inference_steps\": steps\n",
        "}\n",
        "\n",
        "seed = random.randint(0, 1000000000000000000)\n",
        "generator = torch.Generator(device='cuda').manual_seed(seed)\n",
        "\n",
        "pipe = set_sampler(pipe, sampler_name)\n",
        "pipe = set_scheduler(pipe, scheduler_name, steps)\n",
        "\n",
        "sdxl_img = pipe(**params, generator=generator).images[0]\n",
        "\n",
        "sdxl_img.save(os.path.join(save_dir, f\"seed_{seed}_steps_{steps}_{sampler_name}_{scheduler_name}.png\"))\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"Изображение создано и сохранено с параметрами: sampler={sampler_name}, scheduler={scheduler_name}, seed={seed}\")"
      ],
      "metadata": {
        "id": "EPue8FyZ2Ekr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Show** { display-mode: \"form\" }\n",
        "sdxl_img"
      ],
      "metadata": {
        "id": "KzSQS6xK2Ogd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}