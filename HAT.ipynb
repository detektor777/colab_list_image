{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_image/blob/main/HAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xf__D374xeI-"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "!pip install basicsr==1.3.4.9 --no-deps\n",
        "\n",
        "\n",
        "degradations_path = \"/usr/local/lib/python3.11/dist-packages/basicsr/data/degradations.py\"\n",
        "if os.path.exists(degradations_path):\n",
        "    with open(degradations_path, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "    old_import = \"from torchvision.transforms.functional_tensor import rgb_to_grayscale\"\n",
        "    new_import = \"from torchvision.transforms.functional import rgb_to_grayscale\"\n",
        "    if old_import in content:\n",
        "        content = content.replace(old_import, new_import)\n",
        "        with open(degradations_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "        print(f\"Fixed import in {degradations_path}\")\n",
        "    else:\n",
        "        print(f\"Import in {degradations_path} already correct\")\n",
        "\n",
        "if not os.path.exists(\"/content/HAT\"):\n",
        "    print(\"Cloning HAT repository...\")\n",
        "    !git clone https://github.com/XPixelGroup/HAT /content/HAT\n",
        "\n",
        "hat_arch_path = \"/content/HAT/hat/archs/hat_arch.py\"\n",
        "with open(hat_arch_path, 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "if \"ARCH_REGISTRY\" in content:\n",
        "    content = content.replace(\"ARCH_REGISTRY\", \"MODEL_REGISTRY\")\n",
        "if \"from basicsr.utils.registry import MODEL_REGISTRY\" not in content:\n",
        "    content = content.replace(\n",
        "        \"from basicsr.utils.registry import ARCH_REGISTRY\",\n",
        "        \"from basicsr.utils.registry import MODEL_REGISTRY\"\n",
        "    )\n",
        "if \"import torch.nn as nn\" not in content:\n",
        "    content = content.replace(\"import torch\", \"import torch\\nimport torch.nn as nn\")\n",
        "with open(hat_arch_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(content)\n",
        "print(\"Updated hat_arch.py\")\n",
        "\n",
        "os.makedirs(\"/content/uploads\", exist_ok=True)\n",
        "os.makedirs(\"/content/results\", exist_ok=True)\n",
        "print(\"Created folders: /content/uploads, /content/results\")\n",
        "\n",
        "model_path = \"/content/HAT/experiments/pretrained_models/Real_HAT_GAN_sharper.pth\"\n",
        "if not os.path.exists(model_path):\n",
        "    print(\"Downloading Real_HAT_GAN_sharper.pth...\")\n",
        "    !pip install gdown\n",
        "    !gdown --id 1EioFq5-mKmv1uqta_Byd9cgXp9SU3zjj -O {model_path}\n",
        "else:\n",
        "    print(\"Real_HAT_GAN_sharper.pth already exists\")\n",
        "\n",
        "print(\"Setup completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Upload images** { display-mode: \"form\" }\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "upload_folder = \"/content/uploads\"\n",
        "\n",
        "shutil.rmtree(upload_folder, ignore_errors=True)\n",
        "os.makedirs(upload_folder, exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, os.path.join(upload_folder, filename))"
      ],
      "metadata": {
        "id": "b-F-MXuIx6YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Run** { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "import yaml\n",
        "import shutil\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gc\n",
        "from torchvision import transforms\n",
        "import traceback\n",
        "\n",
        "# Подавление предупреждений\n",
        "logging.getLogger(\"torch\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"basicsr\").setLevel(logging.ERROR)\n",
        "\n",
        "# Функция проверки памяти GPU\n",
        "def check_gpu_memory(stage=\"\"):\n",
        "    if torch.cuda.is_available():\n",
        "        total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "        allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "        print(f\"{stage} GPU Memory: Total {total:.2f} GB, Allocated {allocated:.2f} GB\")\n",
        "    else:\n",
        "        print(f\"{stage} GPU not available\")\n",
        "\n",
        "# Очистка памяти в начале\n",
        "print(\"Initial memory cleanup...\")\n",
        "check_gpu_memory(\"Initial\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Initial GPU cache and RAM cleared\")\n",
        "\n",
        "# Проверка доступных моделей\n",
        "print(\"Available pretrained models:\")\n",
        "!ls -lh /content/HAT/experiments/pretrained_models/\n",
        "\n",
        "# Проверка Set5\n",
        "print(\"Checking Set5 dataset...\")\n",
        "!ls /content/uploads/\n",
        "\n",
        "# Очистка после подготовки данных\n",
        "check_gpu_memory(\"Post-data-prep\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Post-data-prep GPU cache and RAM cleared\")\n",
        "\n",
        "# Проверка входных изображений\n",
        "upload_folder = \"/content/uploads\"\n",
        "temp_folder = \"/content/temp_uploads\"\n",
        "print(\"Checking input images:\")\n",
        "for img_name in os.listdir(upload_folder):\n",
        "    img_path = os.path.join(upload_folder, img_name)\n",
        "    if os.path.isfile(img_path):  # Only check files\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            img_array = np.array(img)\n",
        "            print(f\" - {img_name}: {img.size}, format: {img.format}, pixel range: [{img_array.min()}, {img_array.max()}]\")\n",
        "        except Exception as e:\n",
        "            print(f\" - {img_name}: Failed to open ({e})\")\n",
        "    else:\n",
        "        print(f\" - {img_name}: Skipped (not a file)\")\n",
        "\n",
        "# Путь к весам\n",
        "weight_path = \"/content/HAT/experiments/pretrained_models/Real_HAT_GAN_sharper.pth\"\n",
        "if os.path.exists(weight_path):\n",
        "    print(f\"Inspecting weights: {weight_path}\")\n",
        "    checkpoint = torch.load(weight_path, map_location='cpu')\n",
        "    print(\"Available keys in checkpoint:\", list(checkpoint.keys()))\n",
        "    del checkpoint\n",
        "else:\n",
        "    print(f\"Pretrained weights not found at {weight_path}!\")\n",
        "    raise FileNotFoundError(\"Check available models above\")\n",
        "\n",
        "# Проверка весов\n",
        "print(f\"Weights found: {weight_path}, Size: {os.path.getsize(weight_path) / (1024**2):.2f} MB\")\n",
        "\n",
        "# Очистка перед загрузкой модели\n",
        "check_gpu_memory(\"Pre-model-load\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Pre-model-load GPU cache and RAM cleared\")\n",
        "\n",
        "# Добавляем путь к hat в sys.path\n",
        "sys.path.insert(0, \"/content/HAT\")\n",
        "\n",
        "# Импортируем hat.archs\n",
        "try:\n",
        "    import hat.archs\n",
        "except Exception as e:\n",
        "    print(f\"Failed to import hat.archs: {e}\")\n",
        "    raise\n",
        "\n",
        "# Регистрируем HAT в ARCH_REGISTRY\n",
        "from basicsr.utils.registry import ARCH_REGISTRY, MODEL_REGISTRY\n",
        "if \"HAT\" not in ARCH_REGISTRY._obj_map:\n",
        "    try:\n",
        "        hat_class = MODEL_REGISTRY.get(\"HAT\")\n",
        "        if hat_class:\n",
        "            ARCH_REGISTRY.register(hat_class)\n",
        "            print(\"HAT architecture manually registered in ARCH_REGISTRY from MODEL_REGISTRY\")\n",
        "        else:\n",
        "            raise KeyError(\"HAT not found in MODEL_REGISTRY\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Failed to register HAT: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"HAT already registered in ARCH_REGISTRY\")\n",
        "\n",
        "# Вывод зарегистрированных архитектур\n",
        "print(\"Registered architectures:\", list(ARCH_REGISTRY._obj_map.keys()))\n",
        "\n",
        "result_folder = \"/content/results\"\n",
        "\n",
        "# Очистка папки с результатами\n",
        "if os.path.exists(result_folder):\n",
        "    shutil.rmtree(result_folder)\n",
        "os.makedirs(result_folder, exist_ok=True)\n",
        "print(f\"Result folder {result_folder} cleared and recreated\")\n",
        "\n",
        "# Создание временной папки\n",
        "if os.path.exists(temp_folder):\n",
        "    shutil.rmtree(temp_folder)\n",
        "os.makedirs(temp_folder, exist_ok=True)\n",
        "print(f\"Temporary folder {temp_folder} created\")\n",
        "\n",
        "# Функции для обработки изображений с тайлингом\n",
        "def load_and_preprocess_image(image_path):\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    w_orig, h_orig = img.size\n",
        "    print(f\"Original image dimensions: {w_orig}x{h_orig}\")\n",
        "\n",
        "    new_w = ((w_orig + 15) // 16) * 16\n",
        "    new_h = ((h_orig + 15) // 16) * 16\n",
        "\n",
        "    delta_w = new_w - w_orig\n",
        "    delta_h = new_h - h_orig\n",
        "\n",
        "    padding = (delta_w // 2, delta_h // 2, delta_w - delta_w // 2, delta_h - delta_h // 2)\n",
        "\n",
        "    if delta_w != 0 or delta_h != 0:\n",
        "        print(f\"Adding transparent padding to dimensions: {new_w}x{new_h}\")\n",
        "        img = img.crop((-padding[0], -padding[1], w_orig + padding[2], h_orig + padding[3]))\n",
        "    else:\n",
        "        print(\"Image dimensions are already multiples of 16, no padding needed.\")\n",
        "\n",
        "    return img, padding, (w_orig, h_orig)\n",
        "\n",
        "def split_image_into_tiles(img, tile_size):\n",
        "    w, h = img.size\n",
        "    tiles = []\n",
        "    positions = []\n",
        "    for y in range(0, h, tile_size):\n",
        "        for x in range(0, w, tile_size):\n",
        "            tile = img.crop((x, y, min(x + tile_size, w), min(y + tile_size, h)))\n",
        "            tiles.append(tile)\n",
        "            positions.append((x, y))\n",
        "    return tiles, positions\n",
        "\n",
        "def merge_tiles(tiles, positions, img_size):\n",
        "    upscaled_img = Image.new('RGB', img_size)\n",
        "    for tile, (x, y) in zip(tiles, positions):\n",
        "        upscaled_img.paste(tile, (x, y))\n",
        "    return upscaled_img\n",
        "\n",
        "def postprocess_image(tensor):\n",
        "    output = tensor.squeeze(0).cpu().clamp_(0, 1)\n",
        "    output = transforms.ToPILImage()(output)\n",
        "    return output\n",
        "\n",
        "# Конфигурация для Real_HAT_GAN_sharper\n",
        "config = {\n",
        "    \"name\": \"HAT_SRx4_Test\",\n",
        "    \"model_type\": \"HATModel\",\n",
        "    \"scale\": 4,\n",
        "    \"num_gpu\": 1,\n",
        "    \"network_g\": {\n",
        "        \"type\": \"HAT\",\n",
        "        \"upscale\": 4,\n",
        "        \"in_chans\": 3,\n",
        "        \"img_size\": 64,\n",
        "        \"window_size\": 16,\n",
        "        \"img_range\": 1.0,\n",
        "        \"depths\": [6, 6, 6, 6, 6, 6],\n",
        "        \"embed_dim\": 180,\n",
        "        \"num_heads\": [6, 6, 6, 6, 6, 6],\n",
        "        \"mlp_ratio\": 2,\n",
        "        \"upsampler\": \"pixelshuffle\",\n",
        "        \"resi_connection\": \"1conv\"\n",
        "    },\n",
        "    \"path\": {\n",
        "        \"pretrain_network_g\": weight_path,\n",
        "        \"param_key_g\": \"params_ema\",\n",
        "        \"strict_load_g\": False\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"test_y_channel\": False,\n",
        "        \"crop_border\": 4\n",
        "    },\n",
        "    \"val\": {\n",
        "        \"save_img\": True,\n",
        "        \"suffix\": None\n",
        "    },\n",
        "    \"datasets\": {\n",
        "        \"test\": {\n",
        "            \"name\": \"test\",\n",
        "            \"type\": \"SingleImageDataset\",\n",
        "            \"dataroot_lq\": upload_folder,\n",
        "            \"io_backend\": {\"type\": \"disk\"}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Сохранение конфигурации\n",
        "os.makedirs(\"/content/HAT/options/test\", exist_ok=True)\n",
        "with open(\"/content/HAT/options/test/HAT_SRx4_Test.yml\", \"w\") as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "# Очистка перед запуском модели\n",
        "check_gpu_memory(\"Pre-test-pipeline\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Pre-test-pipeline GPU cache and RAM cleared\")\n",
        "\n",
        "# Модифицированный запуск с тайлингом\n",
        "from hat.test import test_pipeline\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Получаем список изображений (только файлы)\n",
        "image_files = [f for f in os.listdir(upload_folder) if os.path.isfile(os.path.join(upload_folder, f))]\n",
        "\n",
        "for filename in image_files:\n",
        "    input_path = os.path.join(upload_folder, filename)\n",
        "    output_path = os.path.join(result_folder, filename)\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nProcessing {filename}\")\n",
        "        # Перемещаем оригинальное изображение во временную папку\n",
        "        temp_input_path = os.path.join(temp_folder, filename)\n",
        "        shutil.move(input_path, temp_input_path)\n",
        "\n",
        "        img, padding, (w_orig, h_orig) = load_and_preprocess_image(temp_input_path)\n",
        "        tile_size = 512\n",
        "        tiles, positions = split_image_into_tiles(img, tile_size)\n",
        "\n",
        "        upscaled_tiles = []\n",
        "        for idx, tile in enumerate(tiles):\n",
        "            print(f\"Processing tile {idx+1}/{len(tiles)}\")\n",
        "            # Очищаем upload_folder (только файлы)\n",
        "            for f in os.listdir(upload_folder):\n",
        "                f_path = os.path.join(upload_folder, f)\n",
        "                if os.path.isfile(f_path):\n",
        "                    os.remove(f_path)\n",
        "\n",
        "            # Сохраняем только текущий тайл в upload_folder\n",
        "            temp_tile_path = os.path.join(upload_folder, f\"tile_{idx}.png\")\n",
        "            tile.save(temp_tile_path)\n",
        "\n",
        "            # Обновляем конфигурацию\n",
        "            config['datasets']['test']['dataroot_lq'] = upload_folder\n",
        "            with open(\"/content/HAT/options/test/HAT_SRx4_Test.yml\", \"w\") as f:\n",
        "                yaml.dump(config, f)\n",
        "\n",
        "            # Запуск test_pipeline\n",
        "            %cd /content/HAT\n",
        "            original_argv = sys.argv\n",
        "            sys.argv = [\"hat/test.py\", \"-opt\", \"options/test/HAT_SRx4_Test.yml\"]\n",
        "            try:\n",
        "                root_path = \"/content/HAT\"\n",
        "                test_pipeline(root_path)\n",
        "                # Находим результат\n",
        "                result_dir = \"results/HAT_SRx4_Test/visualization/test\"\n",
        "                tile_output = [f for f in os.listdir(result_dir) if f.startswith(\"tile_\")][0]\n",
        "                output_image = Image.open(os.path.join(result_dir, tile_output))\n",
        "                upscaled_tiles.append(output_image)\n",
        "                # Очищаем результаты\n",
        "                shutil.rmtree(result_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"Test pipeline failed for tile {idx+1}: {e}\")\n",
        "                raise\n",
        "            finally:\n",
        "                sys.argv = original_argv\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Собираем изображение\n",
        "        scale = 4\n",
        "        upscaled_w = img.size[0] * scale\n",
        "        upscaled_h = img.size[1] * scale\n",
        "        upscaled_img = merge_tiles(upscaled_tiles, [(x * scale, y * scale) for x, y in positions], (upscaled_w, upscaled_h))\n",
        "\n",
        "        pad_left, pad_top, pad_right, pad_bottom = [p * scale for p in padding]\n",
        "        upscaled_img = upscaled_img.crop((pad_left, pad_top, upscaled_w - pad_right, upscaled_h - pad_bottom))\n",
        "\n",
        "        expected_w, expected_h = w_orig * scale, h_orig * scale\n",
        "        upscaled_img = upscaled_img.resize((expected_w, expected_h), Image.LANCZOS)\n",
        "\n",
        "        upscaled_img.save(output_path)\n",
        "        print(f\"Image successfully processed and saved to {output_path}\")\n",
        "\n",
        "        # Возвращаем оригинальное изображение обратно\n",
        "        shutil.move(temp_input_path, input_path)\n",
        "\n",
        "        del img, upscaled_img, upscaled_tiles\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {filename}: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        # Убедимся, что оригинальное изображение возвращено даже при ошибке\n",
        "        if os.path.exists(temp_input_path):\n",
        "            shutil.move(temp_input_path, input_path)\n",
        "\n",
        "# Очистка временной папки\n",
        "if os.path.exists(temp_folder):\n",
        "    shutil.rmtree(temp_folder)\n",
        "print(f\"Temporary folder {temp_folder} removed\")\n",
        "\n",
        "# Очистка после обработки\n",
        "check_gpu_memory(\"Post-results\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Post-results GPU cache and RAM cleared\")\n",
        "\n",
        "# Визуализация результатов с отладкой\n",
        "try:\n",
        "    for fn in os.listdir(result_folder):\n",
        "        result_img = os.path.join(result_folder, fn)\n",
        "        if os.path.exists(result_img):\n",
        "            img = Image.open(result_img)\n",
        "            img_array = np.array(img)\n",
        "            print(f\"Visualizing {fn}: pixel range: [{img_array.min()}, {img_array.max()}]\")\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.title(fn)\n",
        "            plt.imshow(img)\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "            del img, img_array\n",
        "        else:\n",
        "            print(f\"Result image {result_img} not found\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to visualize result: {e}\")\n",
        "\n",
        "# Финальная очистка памяти\n",
        "print(\"Final memory cleanup...\")\n",
        "check_gpu_memory(\"Final\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"Final GPU cache and RAM cleared\")"
      ],
      "metadata": {
        "id": "G4nncnRS7hHw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Visualize** { display-mode: \"form\" }\n",
        "import os\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "def is_image_file(filename):\n",
        "    image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}\n",
        "    return os.path.splitext(filename.lower())[1] in image_extensions\n",
        "\n",
        "def resize_image_maintain_aspect(image, max_width, target_height=None):\n",
        "    width, height = image.size\n",
        "    if width > max_width:\n",
        "        new_height = int(height * max_width / width)\n",
        "        image = image.resize((max_width, new_height), PIL.Image.Resampling.LANCZOS)\n",
        "    if target_height is not None and image.size[1] != target_height:\n",
        "        new_width = int(image.size[0] * target_height / image.size[1])\n",
        "        image = image.resize((new_width, target_height), PIL.Image.Resampling.LANCZOS)\n",
        "    return image\n",
        "\n",
        "def image_to_base64(image):\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "visualization_method = \"Slider\" #@param [\"Side-by-Side\", \"Slider\"]\n",
        "\n",
        "filenames_upload = sorted([f for f in os.listdir(upload_folder) if is_image_file(f)])\n",
        "filenames_upload_output = sorted([f for f in os.listdir(result_folder) if is_image_file(f)])\n",
        "\n",
        "if not filenames_upload or not filenames_upload_output:\n",
        "    print(f\"Error: No images found in {upload_folder} or {result_folder}.\")\n",
        "else:\n",
        "    for filename, filename_output in zip(filenames_upload, filenames_upload_output):\n",
        "        try:\n",
        "            image_original = PIL.Image.open(os.path.join(upload_folder, filename))\n",
        "            image_restore = PIL.Image.open(os.path.join(result_folder, filename_output))\n",
        "\n",
        "            if visualization_method == \"Side-by-Side\":\n",
        "                max_width = 500\n",
        "                image_original = resize_image_maintain_aspect(image_original, max_width)\n",
        "                image_restore = resize_image_maintain_aspect(image_restore, max_width)\n",
        "                target_height = min(image_original.size[1], image_restore.size[1])\n",
        "                image_original = resize_image_maintain_aspect(image_original, max_width, target_height)\n",
        "                image_restore = resize_image_maintain_aspect(image_restore, max_width, target_height)\n",
        "\n",
        "                combined_width = image_original.size[0] + image_restore.size[0]\n",
        "                combined_image = PIL.Image.new('RGB', (combined_width, target_height))\n",
        "                combined_image.paste(image_original, (0, 0))\n",
        "                combined_image.paste(image_restore, (image_original.size[0], 0))\n",
        "                display(combined_image)\n",
        "\n",
        "            else:\n",
        "                max_width = min(image_restore.size[0], 1000)\n",
        "                image_restore = resize_image_maintain_aspect(image_restore, max_width)\n",
        "                target_height = image_restore.size[1]\n",
        "                image_original = resize_image_maintain_aspect(image_original, max_width, target_height)\n",
        "\n",
        "                if image_original.mode != 'RGB':\n",
        "                    image_original = image_original.convert('RGB')\n",
        "                if image_restore.mode != 'RGB':\n",
        "                    image_restore = image_restore.convert('RGB')\n",
        "\n",
        "                original_base64 = image_to_base64(image_original)\n",
        "                restore_base64 = image_to_base64(image_restore)\n",
        "\n",
        "                html_code = f\"\"\"\n",
        "                <div style=\"position: relative; width: {image_restore.size[0]}px; height: {image_restore.size[1]}px; margin-bottom: 20px;\">\n",
        "                    <div style=\"position: relative; width: 100%; height: 100%; overflow: hidden;\">\n",
        "                        <img src=\"data:image/png;base64,{original_base64}\" style=\"position: absolute; width: 100%; height: 100%;\">\n",
        "                        <div style=\"position: absolute; width: 100%; height: 100%; overflow: hidden; clip-path: inset(0 0 0 50%);\">\n",
        "                            <img src=\"data:image/png;base64,{restore_base64}\" style=\"position: absolute; width: 100%; height: 100%;\">\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    <div class=\"slider\" style=\"position: absolute; top: 0; bottom: 0; width: 4px; background: white; cursor: ew-resize; left: 50%; box-shadow: 0 0 5px rgba(0,0,0,0.5);\">\n",
        "                        <div style=\"position: absolute; top: 50%; transform: translateY(-50%); width: 20px; height: 20px; background: white; border-radius: 50%; left: -8px;\"></div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                <script>\n",
        "                    document.querySelectorAll('.slider').forEach(slider => {{\n",
        "                        let isDragging = false;\n",
        "                        const container = slider.parentElement.querySelector('div:nth-child(1)');\n",
        "                        const clipDiv = container.querySelector('div');\n",
        "\n",
        "                        slider.addEventListener('mousedown', (e) => {{\n",
        "                            isDragging = true;\n",
        "                            e.preventDefault();\n",
        "                        }});\n",
        "\n",
        "                        document.addEventListener('mouseup', () => {{\n",
        "                            isDragging = false;\n",
        "                        }});\n",
        "\n",
        "                        document.addEventListener('mousemove', (e) => {{\n",
        "                            if (!isDragging) return;\n",
        "                            const rect = container.getBoundingClientRect();\n",
        "                            let x = e.clientX - rect.left;\n",
        "                            if (x < 0) x = 0;\n",
        "                            if (x > rect.width) x = rect.width;\n",
        "                            const percentage = (x / rect.width) * 100;\n",
        "                            slider.style.left = percentage + '%';\n",
        "                            clipDiv.style.clipPath = `inset(0 0 0 ${{percentage}}%)`;\n",
        "                        }});\n",
        "\n",
        "                        slider.addEventListener('touchstart', (e) => {{\n",
        "                            isDragging = true;\n",
        "                            e.preventDefault();\n",
        "                        }});\n",
        "\n",
        "                        document.addEventListener('touchend', () => {{\n",
        "                            isDragging = false;\n",
        "                        }});\n",
        "\n",
        "                        document.addEventListener('touchmove', (e) => {{\n",
        "                            if (!isDragging) return;\n",
        "                            const rect = container.getBoundingClientRect();\n",
        "                            let x = e.touches[0].clientX - rect.left;\n",
        "                            if (x < 0) x = 0;\n",
        "                            if (x > rect.width) x = rect.width;\n",
        "                            const percentage = (x / rect.width) * 100;\n",
        "                            slider.style.left = percentage + '%';\n",
        "                            clipDiv.style.clipPath = `inset(0 0 0 ${{percentage}}%)`;\n",
        "                        }});\n",
        "                    }});\n",
        "                </script>\n",
        "                \"\"\"\n",
        "\n",
        "                display(HTML(html_code))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename} and {filename_output}: {e}\")"
      ],
      "metadata": {
        "id": "DcjvEqDqyrw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Download results** { display-mode: \"form\" }\n",
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "def is_image_file(filename):\n",
        "    image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}\n",
        "    return os.path.splitext(filename.lower())[1] in image_extensions\n",
        "\n",
        "files_in_folder = [f for f in os.listdir(result_folder) if is_image_file(f)]\n",
        "zip_file = \"download.zip\"\n",
        "\n",
        "if len(files_in_folder) == 1:\n",
        "    file_to_download = os.path.join(result_folder, files_in_folder[0])\n",
        "    files.download(file_to_download)\n",
        "else:\n",
        "    zip_path = os.path.join(result_folder, zip_file)\n",
        "    if os.path.exists(zip_path):\n",
        "        os.remove(zip_path)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for file in files_in_folder:\n",
        "            file_path = os.path.join(result_folder, file)\n",
        "            zipf.write(file_path, file)\n",
        "\n",
        "    files.download(zip_path)"
      ],
      "metadata": {
        "id": "gGNhSD4XyxMc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "eb4bac1e-64af-49ce-b655-afc38fbb42a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_911cfc8c-f0c4-475f-befb-b523673ab1ae\", \"comic1_HAT_SRx4_Test.png\", 268912)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}