{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3RL572dLwxOlaRj+p2L4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_image/blob/main/sd_inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVqr_d1innnK"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "!nvidia-smi\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ª–∏ —É–∂–µ\n",
        "if not os.path.exists('/content/installed_tile_upscaler'):\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üì¶ INSTALLING TILE UPSCALER\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º diffusers –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã\n",
        "    print(\"\\n[1/4] Installing Python packages...\")\n",
        "    packages = [\n",
        "        'diffusers',\n",
        "        'transformers',\n",
        "        'accelerate',\n",
        "        'safetensors',\n",
        "        'invisible-watermark',\n",
        "        'huggingface_hub'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        print(f\"  ‚Üí {package}\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "    print(\"  ‚úì Python packages installed\")\n",
        "\n",
        "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Real-ESRGAN\n",
        "    print(\"\\n[2/4] Installing Real-ESRGAN...\")\n",
        "\n",
        "    if not os.path.exists('/content/Real-ESRGAN'):\n",
        "        print(\"  ‚Üí Cloning repository...\")\n",
        "        get_ipython().system('git clone -q https://github.com/xinntao/Real-ESRGAN.git /content/Real-ESRGAN')\n",
        "\n",
        "    os.chdir('/content/Real-ESRGAN')\n",
        "\n",
        "    print(\"  ‚Üí Installing dependencies...\")\n",
        "    get_ipython().system('pip install -q basicsr facexlib gfpgan -r requirements.txt')\n",
        "    get_ipython().system('python setup.py develop > /dev/null 2>&1')\n",
        "\n",
        "    print(\"  ‚Üí Fixing compatibility issues...\")\n",
        "\n",
        "    # URL –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ GFPGAN\n",
        "    new_model_path = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth'\n",
        "\n",
        "    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª inference_realesrgan.py –∏ –∏–∑–º–µ–Ω—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏\n",
        "    inference_file = '/content/Real-ESRGAN/inference_realesrgan.py'\n",
        "    if os.path.exists(inference_file):\n",
        "        with open(inference_file, 'r') as f:\n",
        "            script_content = f.read()\n",
        "\n",
        "        # –ò–∑–º–µ–Ω—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ —Å–∫—Ä–∏–ø—Ç–∞\n",
        "        new_script_content = re.sub(r\"(model_path\\s*=\\s*[\\\"\\']).*?([\\\"\\'])\", rf\"\\g<1>{new_model_path}\\g<2>\", script_content)\n",
        "\n",
        "        with open(inference_file, 'w') as f:\n",
        "            f.write(new_script_content)\n",
        "\n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é Python\n",
        "    python_version = f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
        "    degradations_path = f'/usr/local/lib/{python_version}/dist-packages/basicsr/data/degradations.py'\n",
        "\n",
        "    # –î–µ–ª–∞–µ–º –±—ç–∫–∞–ø\n",
        "    if os.path.exists(degradations_path):\n",
        "        get_ipython().system(f\"cp -n {degradations_path} {degradations_path}.backup\")\n",
        "\n",
        "    # –§–∏–∫—Å–∏–º –∏–º–ø–æ—Ä—Ç rgb_to_grayscale\n",
        "    get_ipython().system(f\"sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' {degradations_path}\")\n",
        "\n",
        "    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–¥ degradations\n",
        "    degradations_code = '''import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def random_add_gaussian_noise_pt(img, sigma_range=(0, 1.0), gray_prob=0, noise_gray_prob=0, clip=True, rounds=False):\n",
        "    noise_sigma = random.uniform(*sigma_range)\n",
        "\n",
        "    if random.random() < gray_prob:\n",
        "        img = rgb_to_grayscale(img)\n",
        "\n",
        "    if random.random() < noise_gray_prob:\n",
        "        noise = torch.randn(*img.shape[1:], device=img.device) * noise_sigma\n",
        "        noise = noise.unsqueeze(0).repeat(img.shape[0], 1, 1)\n",
        "    else:\n",
        "        noise = torch.randn_like(img) * noise_sigma\n",
        "\n",
        "    out = img + noise\n",
        "\n",
        "    if clip and rounds:\n",
        "        out = torch.clamp((out * 255.0).round(), 0, 255) / 255.\n",
        "    elif clip:\n",
        "        out = torch.clamp(out, 0, 1)\n",
        "    elif rounds:\n",
        "        out = (out * 255.0).round() / 255.\n",
        "\n",
        "    return out\n",
        "\n",
        "def random_add_poisson_noise_pt(img, scale_range=(0, 1.0), gray_prob=0, clip=True, rounds=False):\n",
        "    scale = random.uniform(*scale_range)\n",
        "\n",
        "    if random.random() < gray_prob:\n",
        "        img = rgb_to_grayscale(img)\n",
        "\n",
        "    noise = torch.poisson(img * scale) / scale - img\n",
        "    out = img + noise\n",
        "\n",
        "    if clip and rounds:\n",
        "        out = torch.clamp((out * 255.0).round(), 0, 255) / 255.\n",
        "    elif clip:\n",
        "        out = torch.clamp(out, 0, 1)\n",
        "    elif rounds:\n",
        "        out = (out * 255.0).round() / 255.\n",
        "\n",
        "    return out\n",
        "\n",
        "def rgb_to_grayscale(img):\n",
        "    if img.shape[0] != 3:\n",
        "        raise ValueError('Input image must have 3 channels')\n",
        "    rgb_weights = torch.tensor([0.2989, 0.5870, 0.1140], device=img.device)\n",
        "    grayscale = torch.sum(img * rgb_weights.view(-1, 1, 1), dim=0, keepdim=True)\n",
        "    return grayscale\n",
        "\n",
        "def circular_lowpass_kernel(cutoff, kernel_size, pad_to=0):\n",
        "    if pad_to == 0:\n",
        "        pad_to = kernel_size\n",
        "    assert pad_to >= kernel_size, 'Pad size must be larger than kernel size'\n",
        "\n",
        "    def _scaled_sinc(x):\n",
        "        if x == 0:\n",
        "            return torch.tensor(1.)\n",
        "        x = x * math.pi\n",
        "        return torch.sin(x) / x\n",
        "\n",
        "    half_size = (kernel_size - 1) / 2.\n",
        "    grid = torch.linspace(-half_size, half_size, kernel_size)\n",
        "    x, y = torch.meshgrid(grid, grid)\n",
        "    dist = torch.sqrt(x**2 + y**2)\n",
        "\n",
        "    kernel = _scaled_sinc(dist * cutoff)\n",
        "    kernel = kernel / kernel.sum()\n",
        "\n",
        "    if pad_to > kernel_size:\n",
        "        pad = (pad_to - kernel_size) // 2\n",
        "        kernel = F.pad(kernel, [pad] * 4)\n",
        "\n",
        "    return kernel\n",
        "\n",
        "def random_mixed_kernels(\n",
        "        kernel_list,\n",
        "        kernel_prob,\n",
        "        kernel_size=21,\n",
        "        blur_sigma=0.1,\n",
        "        blur_sigma_min=0.1,\n",
        "        blur_sigma_max=10.0,\n",
        "        blur_kernel_size=21,\n",
        "        pad_to=0):\n",
        "    num_kernels = len(kernel_list)\n",
        "    kernel_type = np.random.choice(kernel_list, p=kernel_prob)\n",
        "\n",
        "    if pad_to == 0:\n",
        "        pad_to = kernel_size\n",
        "\n",
        "    if kernel_type == 'iso':\n",
        "        sigma = np.random.uniform(blur_sigma_min, blur_sigma_max)\n",
        "        kernel = _generate_isotropic_gaussian_kernel(kernel_size, sigma, pad_to)\n",
        "    elif kernel_type == 'aniso':\n",
        "        sigma_x = np.random.uniform(blur_sigma_min, blur_sigma_max)\n",
        "        sigma_y = np.random.uniform(blur_sigma_min, blur_sigma_max)\n",
        "        rotation = np.random.uniform(-np.pi, np.pi)\n",
        "        kernel = _generate_anisotropic_gaussian_kernel(kernel_size, sigma_x, sigma_y, rotation, pad_to)\n",
        "    else:  # general\n",
        "        kernel = circular_lowpass_kernel(blur_sigma, kernel_size, pad_to)\n",
        "\n",
        "    return kernel\n",
        "\n",
        "def _generate_isotropic_gaussian_kernel(kernel_size=21, sigma=0.1, pad_to=0):\n",
        "    if pad_to == 0:\n",
        "        pad_to = kernel_size\n",
        "\n",
        "    half_size = (kernel_size - 1) / 2.\n",
        "    grid = torch.linspace(-half_size, half_size, kernel_size)\n",
        "    x, y = torch.meshgrid(grid, grid)\n",
        "    kernel = torch.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "    kernel = kernel / kernel.sum()\n",
        "\n",
        "    if pad_to > kernel_size:\n",
        "        pad = (pad_to - kernel_size) // 2\n",
        "        kernel = F.pad(kernel, [pad] * 4)\n",
        "\n",
        "    return kernel\n",
        "\n",
        "def _generate_anisotropic_gaussian_kernel(kernel_size=21, sigma_x=0.1, sigma_y=0.1, rotation=0, pad_to=0):\n",
        "    if pad_to == 0:\n",
        "        pad_to = kernel_size\n",
        "\n",
        "    half_size = (kernel_size - 1) / 2.\n",
        "    grid = torch.linspace(-half_size, half_size, kernel_size)\n",
        "    x, y = torch.meshgrid(grid, grid)\n",
        "\n",
        "    cos_theta = torch.cos(torch.tensor(rotation))\n",
        "    sin_theta = torch.sin(torch.tensor(rotation))\n",
        "    x_rot = cos_theta * x - sin_theta * y\n",
        "    y_rot = sin_theta * x + cos_theta * y\n",
        "\n",
        "    kernel = torch.exp(-(x_rot**2 / (2 * sigma_x**2) + y_rot**2 / (2 * sigma_y**2)))\n",
        "    kernel = kernel / kernel.sum()\n",
        "\n",
        "    if pad_to > kernel_size:\n",
        "        pad = (pad_to - kernel_size) // 2\n",
        "        kernel = F.pad(kernel, [pad] * 4)\n",
        "\n",
        "    return kernel\n",
        "'''\n",
        "\n",
        "    with open(degradations_path, 'w') as f:\n",
        "        f.write(degradations_code)\n",
        "\n",
        "    # –ü–∞—Ç—á–∏–º utils.py –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π RealESRGAN\n",
        "    utils_path = '/content/Real-ESRGAN/realesrgan/utils.py'\n",
        "    if os.path.exists(utils_path):\n",
        "        with open(utils_path, 'r') as f:\n",
        "            utils_content = f.read()\n",
        "\n",
        "        # –ò—â–µ–º –∏ –∑–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—É—é —á–∞—Å—Ç—å\n",
        "        old_code = '''        else:\n",
        "            keyname = 'params'\n",
        "        model.load_state_dict(loadnet[keyname], strict=True)'''\n",
        "\n",
        "        new_code = '''        else:\n",
        "            keyname = 'params'\n",
        "\n",
        "        # Support different checkpoint formats\n",
        "        if keyname in loadnet:\n",
        "            model.load_state_dict(loadnet[keyname], strict=True)\n",
        "        else:\n",
        "            # Try to load directly if it's already a state_dict\n",
        "            model.load_state_dict(loadnet, strict=True)'''\n",
        "\n",
        "        if old_code in utils_content:\n",
        "            utils_content = utils_content.replace(old_code, new_code)\n",
        "            with open(utils_path, 'w') as f:\n",
        "                f.write(utils_content)\n",
        "\n",
        "    print(\"  ‚úì Real-ESRGAN installed\")\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è Tile-Upscaler\n",
        "    print(\"\\n[3/4] Creating project structure...\")\n",
        "\n",
        "    if not os.path.exists('/content/Tile-Upscaler'):\n",
        "        get_ipython().system('git clone -q https://github.com/gokayfem/Tile-Upscaler.git /content/Tile-Upscaler')\n",
        "\n",
        "    os.chdir('/content/Tile-Upscaler')\n",
        "\n",
        "    for folder in ['models/ControlNet', 'models/models/Stable-diffusion', 'models/VAE',\n",
        "                   'models/embeddings', 'models/Lora', 'models/upscalers']:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "    print(\"  ‚úì Directories created\")\n",
        "\n",
        "    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—è hf_hub_download\n",
        "    print(\"\\n[4/4] Downloading AI models from Hugging Face...\")\n",
        "    print(\"  (This will take 5-10 minutes)\")\n",
        "\n",
        "    from huggingface_hub import hf_hub_download\n",
        "\n",
        "    models = {\n",
        "        \"Stable Diffusion Model\": {\n",
        "            \"repo_id\": \"dantea1118/juggernaut_reborn\",\n",
        "            \"filename\": \"juggernaut_reborn.safetensors\",\n",
        "            \"local_dir\": \"models/models/Stable-diffusion\"\n",
        "        },\n",
        "        \"RealESRGAN x2\": {\n",
        "            \"repo_id\": \"ai-forever/Real-ESRGAN\",\n",
        "            \"filename\": \"RealESRGAN_x2.pth\",\n",
        "            \"local_dir\": \"models/upscalers/\"\n",
        "        },\n",
        "        \"RealESRGAN x4\": {\n",
        "            \"repo_id\": \"ai-forever/Real-ESRGAN\",\n",
        "            \"filename\": \"RealESRGAN_x4.pth\",\n",
        "            \"local_dir\": \"models/upscalers/\"\n",
        "        },\n",
        "        \"Embedding (BadPrompt)\": {\n",
        "            \"repo_id\": \"philz1337x/embeddings\",\n",
        "            \"filename\": \"verybadimagenegative_v1.3.pt\",\n",
        "            \"local_dir\": \"models/embeddings\"\n",
        "        },\n",
        "        \"Embedding (Juggernaut Neg)\": {\n",
        "            \"repo_id\": \"philz1337x/embeddings\",\n",
        "            \"filename\": \"JuggernautNegative-neg.pt\",\n",
        "            \"local_dir\": \"models/embeddings\"\n",
        "        },\n",
        "        \"LoRA (SDXLrender)\": {\n",
        "            \"repo_id\": \"philz1337x/loras\",\n",
        "            \"filename\": \"SDXLrender_v2.0.safetensors\",\n",
        "            \"local_dir\": \"models/Lora\"\n",
        "        },\n",
        "        \"LoRA (More Details)\": {\n",
        "            \"repo_id\": \"philz1337x/loras\",\n",
        "            \"filename\": \"more_details.safetensors\",\n",
        "            \"local_dir\": \"models/Lora\"\n",
        "        },\n",
        "        \"ControlNet Tile\": {\n",
        "            \"repo_id\": \"lllyasviel/ControlNet-v1-1\",\n",
        "            \"filename\": \"control_v11f1e_sd15_tile.pth\",\n",
        "            \"local_dir\": \"models/ControlNet\"\n",
        "        },\n",
        "        \"VAE\": {\n",
        "            \"repo_id\": \"stabilityai/sd-vae-ft-mse-original\",\n",
        "            \"filename\": \"vae-ft-mse-840000-ema-pruned.safetensors\",\n",
        "            \"local_dir\": \"models/VAE\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    failed_downloads = []\n",
        "\n",
        "    for model_name, model_info in models.items():\n",
        "        file_path = os.path.join(model_info[\"local_dir\"], model_info[\"filename\"])\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"\\n  ‚Üí Downloading {model_name}...\")\n",
        "            try:\n",
        "                hf_hub_download(\n",
        "                    repo_id=model_info[\"repo_id\"],\n",
        "                    filename=model_info[\"filename\"],\n",
        "                    local_dir=model_info[\"local_dir\"]\n",
        "                )\n",
        "                if os.path.exists(file_path):\n",
        "                    size_mb = os.path.getsize(file_path) / (1024*1024)\n",
        "                    print(f\"    ‚úì Downloaded ({size_mb:.1f} MB)\")\n",
        "                else:\n",
        "                    print(f\"    ‚úó Download failed\")\n",
        "                    failed_downloads.append(model_name)\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚úó Error: {str(e)}\")\n",
        "                failed_downloads.append(model_name)\n",
        "        else:\n",
        "            size_mb = os.path.getsize(file_path) / (1024*1024)\n",
        "            print(f\"  ‚úì {model_name} already exists ({size_mb:.1f} MB)\")\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"VERIFYING INSTALLATION\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    all_files = [\n",
        "        'models/ControlNet/control_v11f1e_sd15_tile.pth',\n",
        "        'models/models/Stable-diffusion/juggernaut_reborn.safetensors',\n",
        "        'models/VAE/vae-ft-mse-840000-ema-pruned.safetensors',\n",
        "        'models/embeddings/verybadimagenegative_v1.3.pt',\n",
        "        'models/embeddings/JuggernautNegative-neg.pt',\n",
        "        'models/Lora/SDXLrender_v2.0.safetensors',\n",
        "        'models/Lora/more_details.safetensors',\n",
        "        'models/upscalers/RealESRGAN_x2.pth',\n",
        "        'models/upscalers/RealESRGAN_x4.pth'\n",
        "    ]\n",
        "\n",
        "    missing_files = []\n",
        "    total_size = 0\n",
        "\n",
        "    print(\"\\nInstalled files:\")\n",
        "    for file in all_files:\n",
        "        if os.path.exists(file):\n",
        "            size_mb = os.path.getsize(file) / (1024*1024)\n",
        "            total_size += size_mb\n",
        "            print(f\"  ‚úì {os.path.basename(file)} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"  ‚úó {os.path.basename(file)} - MISSING\")\n",
        "            missing_files.append(file)\n",
        "\n",
        "    print(f\"\\nTotal size: {total_size:.1f} MB\")\n",
        "\n",
        "    if missing_files or failed_downloads:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"‚ö†Ô∏è  INSTALLATION INCOMPLETE\")\n",
        "        print(\"=\" * 70)\n",
        "        if failed_downloads:\n",
        "            print(\"\\nFailed downloads:\")\n",
        "            for item in failed_downloads:\n",
        "                print(f\"  ‚Ä¢ {item}\")\n",
        "        if missing_files:\n",
        "            print(\"\\nMissing files:\")\n",
        "            for file in missing_files:\n",
        "                print(f\"  ‚Ä¢ {os.path.basename(file)}\")\n",
        "        print(\"\\n‚Üí Please run this cell again to retry downloading missing files.\")\n",
        "        print(\"=\" * 70)\n",
        "    else:\n",
        "        # –°–æ–∑–¥–∞–µ–º –º–∞—Ä–∫–µ—Ä —É—Å–ø–µ—à–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
        "        open('/content/installed_tile_upscaler', 'w').close()\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"‚úÖ INSTALLATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"\\nYou can now proceed to:\")\n",
        "        print(\"  ‚Üí Cell 2: Upload your image\")\n",
        "        print(\"  ‚Üí Cell 3: Configure settings\")\n",
        "        print(\"  ‚Üí Cell 4: Process image\")\n",
        "        print(\"  ‚Üí Cell 5: Visualize results\")\n",
        "        print(\"  ‚Üí Cell 6: Download result\")\n",
        "        print(\"=\" * 70)\n",
        "else:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"‚úÖ ALREADY INSTALLED\")\n",
        "    print(\"=\" * 70)\n",
        "    os.chdir('/content/Tile-Upscaler')\n",
        "\n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö\n",
        "    print(\"\\nInstalled models:\")\n",
        "    all_files = [\n",
        "        'models/ControlNet/control_v11f1e_sd15_tile.pth',\n",
        "        'models/models/Stable-diffusion/juggernaut_reborn.safetensors',\n",
        "        'models/VAE/vae-ft-mse-840000-ema-pruned.safetensors',\n",
        "        'models/embeddings/verybadimagenegative_v1.3.pt',\n",
        "        'models/embeddings/JuggernautNegative-neg.pt',\n",
        "        'models/Lora/SDXLrender_v2.0.safetensors',\n",
        "        'models/Lora/more_details.safetensors',\n",
        "        'models/upscalers/RealESRGAN_x2.pth',\n",
        "        'models/upscalers/RealESRGAN_x4.pth'\n",
        "    ]\n",
        "\n",
        "    total_size = 0\n",
        "    for file in all_files:\n",
        "        if os.path.exists(file):\n",
        "            size_mb = os.path.getsize(file) / (1024*1024)\n",
        "            total_size += size_mb\n",
        "            print(f\"  ‚úì {os.path.basename(file)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "    print(f\"\\nTotal size: {total_size:.1f} MB\")\n",
        "    print(\"\\n‚Üí To reinstall: !rm /content/installed_tile_upscaler\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏\n",
        "if '/content/Real-ESRGAN' not in sys.path:\n",
        "    sys.path.insert(0, '/content/Real-ESRGAN')\n",
        "\n",
        "print(\"\\n‚úì Environment ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Upload Image** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "print(\"üìÅ Please select an image to upload...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    input_image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "    input_image.save('/content/input_image.png')\n",
        "\n",
        "    print(f\"‚úÖ Image uploaded successfully: {filename}\")\n",
        "    print(f\"   Size: {input_image.size}\")\n",
        "\n",
        "    #display(input_image)\n",
        "else:\n",
        "    print(\"‚ùå No image uploaded!\")"
      ],
      "metadata": {
        "id": "XakufmW8nru9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Configuration** { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Generation Settings\n",
        "num_inference_steps = 50 #@param {type:\"slider\", min:10, max:100, step:5}\n",
        "guidance_scale = 5 #@param {type:\"slider\", min:1, max:20, step:0.5}\n",
        "scheduler = \"DPM++ 3M SDE Karras\" #@param [\"DDIM\", \"DPM++ 3M SDE Karras\", \"DPM++ 3M Karras\"]\n",
        "\n",
        "#@markdown ### Inpainting Settings\n",
        "inpaint_strength = 0.85 #@param {type:\"slider\", min:0.1, max:1.0, step:0.05}\n",
        "inpaint_controlnet_strength = 0.3 #@param {type:\"slider\", min:0, max:2, step:0.1}\n",
        "mask_blur = 8 #@param {type:\"slider\", min:0, max:50, step:2}\n",
        "\n",
        "#@markdown ### Prompts\n",
        "inpaint_prompt = \"nude\" #@param {type:\"string\"}\n",
        "inpaint_negative_prompt = \"\" #@param {type:\"string\"}\n",
        "custom_prompt = \"Krystal Boyd nude by Luis Royo\" #@param {type:\"string\"}\n",
        "custom_negative_prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Effects\n",
        "face_enhance = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Tiling (for large images)\n",
        "use_tiles = False #@param {type:\"boolean\"}\n",
        "tile_size = 768 #@param {type:\"slider\", min:512, max:1024, step:64}\n",
        "tile_overlap = 128 #@param {type:\"slider\", min:64, max:256, step:32}\n",
        "\n",
        "print(\"‚öôÔ∏è Inpainting configuration saved!\")\n",
        "print(f\"Steps: {num_inference_steps}\")\n",
        "print(f\"Guidance Scale: {guidance_scale}\")\n",
        "print(f\"Scheduler: {scheduler}\")\n",
        "print(f\"Inpaint Strength: {inpaint_strength}\")\n",
        "print(f\"ControlNet Strength: {inpaint_controlnet_strength}\")\n",
        "print(f\"Mask Blur: {mask_blur}\")\n",
        "print(f\"Face Enhancement: {'Enabled' if face_enhance else 'Disabled'}\")\n",
        "print(f\"Use Tiles: {use_tiles}\")\n",
        "if use_tiles:\n",
        "    print(f\"  Tile Size: {tile_size}\")\n",
        "    print(f\"  Tile Overlap: {tile_overlap}\")\n",
        "if inpaint_prompt:\n",
        "    print(f\"Inpaint Prompt: {inpaint_prompt}\")"
      ],
      "metadata": {
        "id": "h6Wfd_TXnxNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Mask** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import output\n",
        "from IPython.display import display, HTML, Image as IPImage\n",
        "from PIL import Image, ImageDraw\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "brush_size = 40  #@param {type:\"slider\", min:10, max:200, step:5}\n",
        "brush_opacity = 0.5  #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "\n",
        "input_image = Image.open('/content/input_image.png')\n",
        "\n",
        "buffered = BytesIO()\n",
        "input_image.save(buffered, format=\"PNG\")\n",
        "img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "html_code = f\"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "    #container {{\n",
        "        position: relative;\n",
        "        display: inline-block;\n",
        "    }}\n",
        "    #imageCanvas, #maskCanvas {{\n",
        "        position: absolute;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        cursor: crosshair;\n",
        "    }}\n",
        "    #maskCanvas {{\n",
        "        opacity: 0.5;\n",
        "    }}\n",
        "    .controls {{\n",
        "        margin: 10px 0;\n",
        "    }}\n",
        "    button {{\n",
        "        padding: 10px 20px;\n",
        "        margin: 5px;\n",
        "        font-size: 14px;\n",
        "        cursor: pointer;\n",
        "    }}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"controls\">\n",
        "    <button onclick=\"clearMask()\">üóëÔ∏è Clear Mask</button>\n",
        "    <button onclick=\"saveMask()\">üíæ Save Mask</button>\n",
        "    <button onclick=\"toggleMaskVisibility()\">üëÅÔ∏è Toggle Mask</button>\n",
        "    <span id=\"status\" style=\"margin-left: 20px; font-weight: bold;\"></span>\n",
        "</div>\n",
        "<div id=\"container\">\n",
        "    <canvas id=\"imageCanvas\"></canvas>\n",
        "    <canvas id=\"maskCanvas\"></canvas>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "const imageCanvas = document.getElementById('imageCanvas');\n",
        "const maskCanvas = document.getElementById('maskCanvas');\n",
        "const imageCtx = imageCanvas.getContext('2d');\n",
        "const maskCtx = maskCanvas.getContext('2d');\n",
        "\n",
        "const img = new Image();\n",
        "img.src = 'data:image/png;base64,{img_str}';\n",
        "\n",
        "img.onload = function() {{\n",
        "    const maxWidth = Math.min(img.width, 1200);\n",
        "    const scale = maxWidth / img.width;\n",
        "    const width = img.width * scale;\n",
        "    const height = img.height * scale;\n",
        "\n",
        "    imageCanvas.width = width;\n",
        "    imageCanvas.height = height;\n",
        "    maskCanvas.width = width;\n",
        "    maskCanvas.height = height;\n",
        "\n",
        "    imageCtx.drawImage(img, 0, 0, width, height);\n",
        "\n",
        "    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–µ–ª—ã–π —Ñ–æ–Ω –¥–ª—è –º–∞—Å–∫–∏\n",
        "    maskCtx.fillStyle = 'white';\n",
        "    maskCtx.fillRect(0, 0, width, height);\n",
        "}};\n",
        "\n",
        "let isDrawing = false;\n",
        "let brushSize = {brush_size};\n",
        "let brushOpacity = {brush_opacity};\n",
        "\n",
        "maskCanvas.addEventListener('mousedown', startDrawing);\n",
        "maskCanvas.addEventListener('mousemove', draw);\n",
        "maskCanvas.addEventListener('mouseup', stopDrawing);\n",
        "maskCanvas.addEventListener('mouseout', stopDrawing);\n",
        "\n",
        "// Touch events –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤\n",
        "maskCanvas.addEventListener('touchstart', handleTouch);\n",
        "maskCanvas.addEventListener('touchmove', handleTouch);\n",
        "maskCanvas.addEventListener('touchend', stopDrawing);\n",
        "\n",
        "function startDrawing(e) {{\n",
        "    isDrawing = true;\n",
        "    draw(e);\n",
        "}}\n",
        "\n",
        "function stopDrawing() {{\n",
        "    isDrawing = false;\n",
        "}}\n",
        "\n",
        "function draw(e) {{\n",
        "    if (!isDrawing) return;\n",
        "\n",
        "    const rect = maskCanvas.getBoundingClientRect();\n",
        "    const x = e.clientX - rect.left;\n",
        "    const y = e.clientY - rect.top;\n",
        "\n",
        "    maskCtx.fillStyle = `rgba(0, 0, 0, ${{brushOpacity}})`;\n",
        "    maskCtx.beginPath();\n",
        "    maskCtx.arc(x, y, brushSize / 2, 0, Math.PI * 2);\n",
        "    maskCtx.fill();\n",
        "}}\n",
        "\n",
        "function handleTouch(e) {{\n",
        "    e.preventDefault();\n",
        "    const touch = e.touches[0];\n",
        "    const mouseEvent = new MouseEvent(e.type === 'touchstart' ? 'mousedown' : 'mousemove', {{\n",
        "        clientX: touch.clientX,\n",
        "        clientY: touch.clientY\n",
        "    }});\n",
        "    maskCanvas.dispatchEvent(mouseEvent);\n",
        "}}\n",
        "\n",
        "function clearMask() {{\n",
        "    maskCtx.fillStyle = 'white';\n",
        "    maskCtx.fillRect(0, 0, maskCanvas.width, maskCanvas.height);\n",
        "    document.getElementById('status').textContent = '‚úì Mask cleared';\n",
        "    setTimeout(() => {{ document.getElementById('status').textContent = ''; }}, 2000);\n",
        "}}\n",
        "\n",
        "function toggleMaskVisibility() {{\n",
        "    if (maskCanvas.style.opacity === '0') {{\n",
        "        maskCanvas.style.opacity = '0.5';\n",
        "    }} else {{\n",
        "        maskCanvas.style.opacity = '0';\n",
        "    }}\n",
        "}}\n",
        "\n",
        "function saveMask() {{\n",
        "    // –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π canvas –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Å–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É\n",
        "    const tempCanvas = document.createElement('canvas');\n",
        "    tempCanvas.width = img.width;\n",
        "    tempCanvas.height = img.height;\n",
        "    const tempCtx = tempCanvas.getContext('2d');\n",
        "\n",
        "    tempCtx.drawImage(maskCanvas, 0, 0, img.width, img.height);\n",
        "\n",
        "    const maskData = tempCanvas.toDataURL('image/png');\n",
        "\n",
        "    google.colab.kernel.invokeFunction('notebook.save_mask', [maskData], {{}});\n",
        "\n",
        "    document.getElementById('status').textContent = '‚úì Mask saved!';\n",
        "    setTimeout(() => {{ document.getElementById('status').textContent = ''; }}, 2000);\n",
        "}}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "def save_mask(mask_data):\n",
        "    mask_data = mask_data.split(',')[1]\n",
        "    mask_bytes = base64.b64decode(mask_data)\n",
        "    mask_image = Image.open(BytesIO(mask_bytes))\n",
        "\n",
        "    mask_image.save('/content/inpaint_mask.png')\n",
        "    print(\"‚úÖ Mask saved to /content/inpaint_mask.png\")\n",
        "\n",
        "output.register_callback('notebook.save_mask', save_mask)\n",
        "\n",
        "display(HTML(html_code))\n",
        "\n",
        "print(\"üé® Draw on the image to create inpainting mask\")\n",
        "print(\"   Black areas = will be inpainted\")\n",
        "print(\"   White areas = will be kept unchanged\")"
      ],
      "metadata": {
        "id": "rUnHfIJmn5bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Run** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import warnings\n",
        "from diffusers import StableDiffusionControlNetInpaintPipeline, ControlNetModel, DDIMScheduler, DPMSolverMultistepScheduler\n",
        "from diffusers.models import AutoencoderKL\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "os.chdir('/content/Tile-Upscaler')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def get_scheduler(scheduler_name, config):\n",
        "    if scheduler_name == \"DDIM\":\n",
        "        return DDIMScheduler.from_config(config)\n",
        "    elif scheduler_name == \"DPM++ 3M SDE Karras\":\n",
        "        return DPMSolverMultistepScheduler.from_config(config, algorithm_type=\"sde-dpmsolver++\", use_karras_sigmas=True)\n",
        "    elif scheduler_name == \"DPM++ 3M Karras\":\n",
        "        return DPMSolverMultistepScheduler.from_config(config, algorithm_type=\"dpmsolver++\", use_karras_sigmas=True)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown scheduler: {scheduler_name}\")\n",
        "\n",
        "if 'inpaint_pipe' not in globals():\n",
        "    print(\"üîÑ Loading inpainting models...\")\n",
        "\n",
        "    from diffusers.utils import logging as diffusers_logging\n",
        "    diffusers_logging.set_verbosity_error()\n",
        "\n",
        "    controlnet = ControlNetModel.from_single_file(\n",
        "        \"models/ControlNet/control_v11f1e_sd15_tile.pth\",\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "    inpaint_pipe = StableDiffusionControlNetInpaintPipeline.from_single_file(\n",
        "        \"models/models/Stable-diffusion/juggernaut_reborn.safetensors\",\n",
        "        controlnet=controlnet,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        safety_checker=None\n",
        "    )\n",
        "\n",
        "    vae = AutoencoderKL.from_single_file(\n",
        "        \"models/VAE/vae-ft-mse-840000-ema-pruned.safetensors\",\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "    inpaint_pipe.vae = vae\n",
        "\n",
        "    inpaint_pipe.load_textual_inversion(\"models/embeddings/verybadimagenegative_v1.3.pt\")\n",
        "    inpaint_pipe.load_textual_inversion(\"models/embeddings/JuggernautNegative-neg.pt\")\n",
        "    inpaint_pipe.load_lora_weights(\"models/Lora/SDXLrender_v2.0.safetensors\")\n",
        "    inpaint_pipe.fuse_lora(lora_scale=0.5)\n",
        "    inpaint_pipe.load_lora_weights(\"models/Lora/more_details.safetensors\")\n",
        "    inpaint_pipe.fuse_lora(lora_scale=1.)\n",
        "\n",
        "    inpaint_pipe.enable_freeu(s1=0.9, s2=0.2, b1=1.3, b2=1.4)\n",
        "    inpaint_pipe.to(device)\n",
        "    inpaint_pipe.set_progress_bar_config(disable=True)\n",
        "\n",
        "    print(\"‚úÖ Inpainting models loaded!\")\n",
        "\n",
        "inpaint_pipe.scheduler = get_scheduler(scheduler, inpaint_pipe.scheduler.config)\n",
        "\n",
        "if not os.path.exists('/content/inpaint_mask.png'):\n",
        "    raise FileNotFoundError(\"‚ùå Mask not found! Please create a mask first using cell 5.\")\n",
        "\n",
        "input_image = Image.open('/content/input_image.png').convert(\"RGB\")\n",
        "mask_image = Image.open('/content/inpaint_mask.png').convert(\"L\")\n",
        "\n",
        "\n",
        "mask_image = ImageOps.invert(mask_image)\n",
        "\n",
        "if mask_blur > 0:\n",
        "    mask_image = mask_image.filter(ImageFilter.GaussianBlur(radius=mask_blur))\n",
        "\n",
        "print(\"üé® Processing inpainting...\")\n",
        "start_time = time.time()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "W, H = input_image.size\n",
        "\n",
        "final_prompt = inpaint_prompt if inpaint_prompt else (custom_prompt if custom_prompt else \"masterpiece, best quality, highres, detailed\")\n",
        "final_negative = inpaint_negative_prompt if inpaint_negative_prompt else (custom_negative_prompt if custom_negative_prompt else \"low quality, normal quality, ugly, blurry, blur, lowres, bad anatomy, bad hands, cropped, worst quality, verybadimagenegative_v1.3, JuggernautNegative-neg\")\n",
        "\n",
        "def process_inpainting_tile(image, mask, control_image, tile_bbox):\n",
        "    left, top, right, bottom = tile_bbox\n",
        "\n",
        "    tile_image = image.crop(tile_bbox)\n",
        "    tile_mask = mask.crop(tile_bbox)\n",
        "    tile_control = control_image.crop(tile_bbox)\n",
        "\n",
        "    options = {\n",
        "        \"prompt\": final_prompt,\n",
        "        \"negative_prompt\": final_negative,\n",
        "        \"image\": tile_image,\n",
        "        \"mask_image\": tile_mask,\n",
        "        \"control_image\": tile_control,\n",
        "        \"num_inference_steps\": num_inference_steps,\n",
        "        \"strength\": inpaint_strength,\n",
        "        \"guidance_scale\": guidance_scale,\n",
        "        \"controlnet_conditioning_scale\": float(inpaint_controlnet_strength),\n",
        "        \"generator\": torch.Generator(device=device).manual_seed(random.randint(0, 2147483647)),\n",
        "    }\n",
        "\n",
        "    return np.array(inpaint_pipe(**options).images[0])\n",
        "\n",
        "def create_weight_mask(size, edge_fade=32):\n",
        "    \"\"\"–°–æ–∑–¥–∞–µ—Ç –º–∞—Å–∫—É –≤–µ—Å–æ–≤ –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Ç–∞–π–ª–æ–≤\"\"\"\n",
        "    w, h = size\n",
        "    weight = np.ones((h, w), dtype=np.float32)\n",
        "\n",
        "    for i in range(edge_fade):\n",
        "        alpha = i / edge_fade\n",
        "        weight[i, :] *= alpha\n",
        "        weight[h-1-i, :] *= alpha\n",
        "        weight[:, i] *= alpha\n",
        "        weight[:, w-1-i] *= alpha\n",
        "\n",
        "    return weight\n",
        "\n",
        "if use_tiles and (W > tile_size or H > tile_size):\n",
        "    num_tiles_x = math.ceil(W / (tile_size - tile_overlap))\n",
        "    num_tiles_y = math.ceil(H / (tile_size - tile_overlap))\n",
        "\n",
        "    result = np.zeros((H, W, 3), dtype=np.float32)\n",
        "    weight_sum = np.zeros((H, W, 1), dtype=np.float32)\n",
        "\n",
        "    total_tiles = num_tiles_x * num_tiles_y\n",
        "    tiles_processed = 0\n",
        "\n",
        "    with tqdm(total=total_tiles, desc=\"Processing tiles\", unit=\"tile\") as pbar:\n",
        "        for i in range(num_tiles_y):\n",
        "            for j in range(num_tiles_x):\n",
        "                left = j * (tile_size - tile_overlap)\n",
        "                top = i * (tile_size - tile_overlap)\n",
        "                right = min(left + tile_size, W)\n",
        "                bottom = min(top + tile_size, H)\n",
        "\n",
        "                tile_mask_array = np.array(mask_image.crop((left, top, right, bottom)))\n",
        "                if tile_mask_array.max() == 0:\n",
        "                    original_tile = np.array(input_image.crop((left, top, right, bottom)))\n",
        "                    tile_h, tile_w = original_tile.shape[:2]\n",
        "                    tile_weight = np.ones((tile_h, tile_w), dtype=np.float32)\n",
        "\n",
        "                    result[top:bottom, left:right] += original_tile * tile_weight[:, :, np.newaxis]\n",
        "                    weight_sum[top:bottom, left:right] += tile_weight[:, :, np.newaxis]\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "                tile_bbox = (left, top, right, bottom)\n",
        "                result_tile = process_inpainting_tile(input_image, mask_image, input_image, tile_bbox)\n",
        "                tiles_processed += 1\n",
        "\n",
        "                tile_h, tile_w = result_tile.shape[:2]\n",
        "                tile_weight = create_weight_mask((tile_w, tile_h), edge_fade=tile_overlap//4)\n",
        "\n",
        "                result[top:bottom, left:right] += result_tile * tile_weight[:, :, np.newaxis]\n",
        "                weight_sum[top:bottom, left:right] += tile_weight[:, :, np.newaxis]\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "    result = np.where(weight_sum > 0, result / weight_sum, 0).astype(np.uint8)\n",
        "    output_image = Image.fromarray(result)\n",
        "\n",
        "else:\n",
        "    print(\"Processing full image...\")\n",
        "\n",
        "    options = {\n",
        "        \"prompt\": final_prompt,\n",
        "        \"negative_prompt\": final_negative,\n",
        "        \"image\": input_image,\n",
        "        \"mask_image\": mask_image,\n",
        "        \"control_image\": input_image,\n",
        "        \"num_inference_steps\": num_inference_steps,\n",
        "        \"strength\": inpaint_strength,\n",
        "        \"guidance_scale\": guidance_scale,\n",
        "        \"controlnet_conditioning_scale\": float(inpaint_controlnet_strength),\n",
        "        \"generator\": torch.Generator(device=device).manual_seed(random.randint(0, 2147483647)),\n",
        "    }\n",
        "\n",
        "    output_image = inpaint_pipe(**options).images[0]\n",
        "\n",
        "if face_enhance:\n",
        "    print(\"üë§ Enhancing faces...\")\n",
        "    if 'lazy_gfpgan' not in globals():\n",
        "        from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "\n",
        "        class LazyGFPGAN:\n",
        "            def __init__(self, device):\n",
        "                self.device = device\n",
        "                self.model = None\n",
        "\n",
        "            def load_model(self):\n",
        "                if self.model is None:\n",
        "                    from gfpgan import GFPGANer\n",
        "                    model_path = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth'\n",
        "                    self.model = GFPGANer(\n",
        "                        model_path=model_path,\n",
        "                        upscale=1,\n",
        "                        arch='clean',\n",
        "                        channel_multiplier=2,\n",
        "                        bg_upsampler=None,\n",
        "                        device=self.device\n",
        "                    )\n",
        "\n",
        "            def enhance(self, img):\n",
        "                self.load_model()\n",
        "                img_np = np.array(img)\n",
        "                img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
        "                _, _, output = self.model.enhance(img_bgr, has_aligned=False, only_center_face=False, paste_back=True)\n",
        "                output_rgb = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "                return Image.fromarray(output_rgb)\n",
        "\n",
        "        lazy_gfpgan = LazyGFPGAN(device)\n",
        "\n",
        "    output_image = lazy_gfpgan.enhance(output_image)\n",
        "\n",
        "output_image.save('/content/inpaint_output.png')\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"‚úÖ Done in {end_time - start_time:.1f}s | Size: {output_image.size}\")\n",
        "print(f\"üíæ Saved to: /content/inpaint_output.png\")"
      ],
      "metadata": {
        "id": "W7i3ivSooMi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Visualize** { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from IPython.display import HTML, display\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "#@markdown ### Visualization Method\n",
        "visualization_method = \"Slider\" #@param [\"Side-by-Side\", \"Slider\"]\n",
        "\n",
        "def resize_image_maintain_aspect(image, max_width, target_height=None):\n",
        "    width, height = image.size\n",
        "    if width > max_width:\n",
        "        new_height = int(height * max_width / width)\n",
        "        image = image.resize((max_width, new_height), PIL.Image.LANCZOS)\n",
        "    if target_height is not None and image.size[1] != target_height:\n",
        "        new_width = int(image.size[0] * target_height / image.size[1])\n",
        "        image = image.resize((new_width, target_height), PIL.Image.LANCZOS)\n",
        "    return image\n",
        "\n",
        "def image_to_base64(image):\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "if not os.path.exists('/content/input_image.png') or not os.path.exists('/content/inpaint_output.png'):\n",
        "    print(\"‚ùå Error: Images not found. Please run the processing step first.\")\n",
        "else:\n",
        "    image_original = PIL.Image.open('/content/input_image.png')\n",
        "    image_restore = PIL.Image.open('/content/inpaint_output.png')\n",
        "\n",
        "    if visualization_method == \"Side-by-Side\":\n",
        "        max_width = 500\n",
        "        image_original = resize_image_maintain_aspect(image_original, max_width)\n",
        "        image_restore = resize_image_maintain_aspect(image_restore, max_width)\n",
        "        target_height = min(image_original.size[1], image_restore.size[1])\n",
        "        image_original = resize_image_maintain_aspect(image_original, max_width, target_height)\n",
        "        image_restore = resize_image_maintain_aspect(image_restore, max_width, target_height)\n",
        "\n",
        "        combined_width = image_original.size[0] + image_restore.size[0]\n",
        "        combined_image = PIL.Image.new('RGB', (combined_width, target_height))\n",
        "        combined_image.paste(image_original, (0, 0))\n",
        "        combined_image.paste(image_restore, (image_original.size[0], 0))\n",
        "        display(combined_image)\n",
        "\n",
        "    else:  # Slider\n",
        "        max_width = min(image_restore.size[0], 1000)\n",
        "        image_restore = resize_image_maintain_aspect(image_restore, max_width)\n",
        "        target_height = image_restore.size[1]\n",
        "        image_original = resize_image_maintain_aspect(image_original, max_width, target_height)\n",
        "\n",
        "        if image_original.mode != 'RGB':\n",
        "            image_original = image_original.convert('RGB')\n",
        "        if image_restore.mode != 'RGB':\n",
        "            image_restore = image_restore.convert('RGB')\n",
        "\n",
        "        original_base64 = image_to_base64(image_original)\n",
        "        restore_base64 = image_to_base64(image_restore)\n",
        "\n",
        "        html_code = f\"\"\"\n",
        "        <div style=\"position: relative; width: {image_restore.size[0]}px; height: {image_restore.size[1]}px; margin: 20px auto;\">\n",
        "            <div style=\"position: relative; width: 100%; height: 100%; overflow: hidden;\">\n",
        "                <img src=\"data:image/png;base64,{original_base64}\" style=\"position: absolute; width: 100%; height: 100%;\">\n",
        "                <div style=\"position: absolute; width: 100%; height: 100%; overflow: hidden; clip-path: inset(0 0 0 50%);\">\n",
        "                    <img src=\"data:image/png;base64,{restore_base64}\" style=\"position: absolute; width: 100%; height: 100%;\">\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"slider\" style=\"position: absolute; top: 0; bottom: 0; width: 4px; background: white; cursor: ew-resize; left: 50%; box-shadow: 0 0 5px rgba(0,0,0,0.5);\">\n",
        "                <div style=\"position: absolute; top: 50%; transform: translateY(-50%); width: 20px; height: 20px; background: white; border-radius: 50%; left: -8px;\"></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        <script>\n",
        "            (function() {{\n",
        "                const slider = document.querySelector('.slider');\n",
        "                if (!slider) return;\n",
        "\n",
        "                let isDragging = false;\n",
        "                const container = slider.parentElement.querySelector('div:nth-child(1)');\n",
        "                const clipDiv = container.querySelector('div');\n",
        "\n",
        "                slider.addEventListener('mousedown', (e) => {{\n",
        "                    isDragging = true;\n",
        "                    e.preventDefault();\n",
        "                }});\n",
        "\n",
        "                document.addEventListener('mouseup', () => {{\n",
        "                    isDragging = false;\n",
        "                }});\n",
        "\n",
        "                document.addEventListener('mousemove', (e) => {{\n",
        "                    if (!isDragging) return;\n",
        "                    const rect = container.getBoundingClientRect();\n",
        "                    let x = e.clientX - rect.left;\n",
        "                    if (x < 0) x = 0;\n",
        "                    if (x > rect.width) x = rect.width;\n",
        "                    const percentage = (x / rect.width) * 100;\n",
        "                    slider.style.left = percentage + '%';\n",
        "                    clipDiv.style.clipPath = `inset(0 0 0 ${{percentage}}%)`;\n",
        "                }});\n",
        "\n",
        "                slider.addEventListener('touchstart', (e) => {{\n",
        "                    isDragging = true;\n",
        "                    e.preventDefault();\n",
        "                }});\n",
        "\n",
        "                document.addEventListener('touchend', () => {{\n",
        "                    isDragging = false;\n",
        "                }});\n",
        "\n",
        "                document.addEventListener('touchmove', (e) => {{\n",
        "                    if (!isDragging) return;\n",
        "                    const rect = container.getBoundingClientRect();\n",
        "                    let x = e.touches[0].clientX - rect.left;\n",
        "                    if (x < 0) x = 0;\n",
        "                    if (x > rect.width) x = rect.width;\n",
        "                    const percentage = (x / rect.width) * 100;\n",
        "                    slider.style.left = percentage + '%';\n",
        "                    clipDiv.style.clipPath = `inset(0 0 0 ${{percentage}}%)`;\n",
        "                }});\n",
        "            }})();\n",
        "        </script>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(html_code))"
      ],
      "metadata": {
        "id": "jLzXDylIoS40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Download** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "#@markdown ### Download Options\n",
        "download_result = True  #@param {type:\"boolean\"}\n",
        "download_mask = False  #@param {type:\"boolean\"}\n",
        "\n",
        "if download_result and os.path.exists('/content/inpaint_output.png'):\n",
        "    print(\"üíæ Downloading inpainted image...\")\n",
        "    files.download('/content/inpaint_output.png')\n",
        "    print(\"‚úÖ Inpainted image download started!\")\n",
        "else:\n",
        "    if not os.path.exists('/content/inpaint_output.png'):\n",
        "        print(\"‚ùå No inpainted image found! Please run the inpainting step first.\")\n",
        "\n",
        "if download_mask and os.path.exists('/content/inpaint_mask.png'):\n",
        "    print(\"üíæ Downloading mask...\")\n",
        "    files.download('/content/inpaint_mask.png')\n",
        "    print(\"‚úÖ Mask download started!\")\n",
        "else:\n",
        "    if download_mask and not os.path.exists('/content/inpaint_mask.png'):\n",
        "        print(\"‚ùå No mask found!\")"
      ],
      "metadata": {
        "id": "STzxTLw8oWOY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}